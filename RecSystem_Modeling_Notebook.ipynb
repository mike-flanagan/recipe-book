{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<head><h1 align=\"center\">\n",
    "Food.com Recipe Interactions\n",
    "</h1></head>  \n",
    "  \n",
    "<head><h3 align=\"center\">Recipe Recommender System Modeling</h3></head>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will develop a **personalized recommender system**. With such systems, there are different options for methods in which to approach recommendations:\n",
    "  \n",
    "- The first method is to ask for *explicit* defined ratings from a user regarding the content that they have used/viewed/consumed.  \n",
    "\n",
    "- Another method is to gather data *implicitly* as the user interacts with the system or service.\n",
    "  \n",
    "In this dataset, we have both:  \n",
    "- **Explicit Data** — the `rating` feature of the **interactions dataset** for each `user`.\n",
    "- **Implicit Data** — the `x` feature of the **x dataset**.  \n",
    "  \n",
    "Technically, I would suppose the `review` feature would fall under explicit data as well, but to use it as such would require *Natural Language Processing*, which we may get involved in later, but not in this notebook.  \n",
    "  \n",
    "Additionally with personalized recommender systems, we can center our system around either around suggesting similar *content* (recipes) or suggestions based on other *users of similar preference*. Both systems are succinctly described below:\n",
    "  \n",
    "**Content-Based Recommenders**  \n",
    "> Main Idea: If you like an item, you will also like \"similar\" items.$_1$  \n",
    "  \n",
    "**Collaborative Filtering Systems**  \n",
    "> Main Idea: If user A likes items 5, 6, 7, and 8 and user B likes items 5, 6, and 7, then it is highly likely that user B will also like item 8.$_1$  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os import system\n",
    "from math import floor\n",
    "from copy import deepcopy\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise.prediction_algorithms import knns, SVD\n",
    "from surprise.similarities import cosine, msd, pearson\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('data/RAW_recipes.csv')\n",
    "int_df = pd.read_csv('data/RAW_interactions.csv')\n",
    "tdf = pd.read_csv('data/interactions_train.csv')\n",
    "vdf = pd.read_csv('data/interactions_validation.csv')\n",
    "\n",
    "# \"\"\"Cleaning: All steps carried over from EDA Notebook\"\"\"\n",
    "df.drop(labels=721, inplace = True)\n",
    "\n",
    "# Cleaning/FE: Creating columns for recipe's respective nutrients\n",
    "df['kcal'] = df.nutrition.apply(lambda x: x[1:-1].split(sep=', ')[0])\n",
    "df['fat'] = df.nutrition.apply(lambda x: x[1:-1].split(sep=', ')[1])\n",
    "df['sugar'] = df.nutrition.apply(lambda x: x[1:-1].split(sep=', ')[2])\n",
    "df['salt'] = df.nutrition.apply(lambda x: x[1:-1].split(sep=', ')[3])\n",
    "df['protein'] = df.nutrition.apply(lambda x: x[1:-1].split(sep=', ')[4])\n",
    "df['sat_fat'] = df.nutrition.apply(lambda x: x[1:-1].split(sep=', ')[5])\n",
    "df['carbs'] = df.nutrition.apply(lambda x: x[1:-1].split(sep=', ')[6])\n",
    "\n",
    "# Cleaning: Imputing outlier value to median\n",
    "df['minutes'] = np.where(df.minutes == 2147483647,\n",
    "                         df.minutes.median(),\n",
    "                         df.minutes)\n",
    "\n",
    "# Setting these two dataframes to independent .head() call sizes for ease of access\n",
    "idf = int_df.head(11)\n",
    "rdf = df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>Great with a salad. Cooked on top of stove for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>5</td>\n",
       "      <td>So simple, so delicious! Great for chilly fall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>This worked very well and is EASY.  I used not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I made the Mexican topping and took it to bunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Made the cheddar bacon topping, adding a sprin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52282</td>\n",
       "      <td>120345</td>\n",
       "      <td>2005-05-21</td>\n",
       "      <td>4</td>\n",
       "      <td>very very sweet. after i waited the 2 days i b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124416</td>\n",
       "      <td>120345</td>\n",
       "      <td>2011-08-06</td>\n",
       "      <td>0</td>\n",
       "      <td>Just an observation, so I will not rate.  I fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000192946</td>\n",
       "      <td>120345</td>\n",
       "      <td>2015-05-10</td>\n",
       "      <td>2</td>\n",
       "      <td>This recipe was OVERLY too sweet.  I would sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76535</td>\n",
       "      <td>134728</td>\n",
       "      <td>2005-09-02</td>\n",
       "      <td>4</td>\n",
       "      <td>Very good!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>273745</td>\n",
       "      <td>134728</td>\n",
       "      <td>2005-12-22</td>\n",
       "      <td>5</td>\n",
       "      <td>Better than the real!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>353911</td>\n",
       "      <td>134728</td>\n",
       "      <td>2006-09-26</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely AWESOME! I was speechless when I tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  recipe_id        date  rating  \\\n",
       "0        38094      40893  2003-02-17       4   \n",
       "1      1293707      40893  2011-12-21       5   \n",
       "2         8937      44394  2002-12-01       4   \n",
       "3       126440      85009  2010-02-27       5   \n",
       "4        57222      85009  2011-10-01       5   \n",
       "5        52282     120345  2005-05-21       4   \n",
       "6       124416     120345  2011-08-06       0   \n",
       "7   2000192946     120345  2015-05-10       2   \n",
       "8        76535     134728  2005-09-02       4   \n",
       "9       273745     134728  2005-12-22       5   \n",
       "10      353911     134728  2006-09-26       5   \n",
       "\n",
       "                                               review  \n",
       "0   Great with a salad. Cooked on top of stove for...  \n",
       "1   So simple, so delicious! Great for chilly fall...  \n",
       "2   This worked very well and is EASY.  I used not...  \n",
       "3   I made the Mexican topping and took it to bunk...  \n",
       "4   Made the cheddar bacon topping, adding a sprin...  \n",
       "5   very very sweet. after i waited the 2 days i b...  \n",
       "6   Just an observation, so I will not rate.  I fo...  \n",
       "7   This recipe was OVERLY too sweet.  I would sta...  \n",
       "8                                          Very good!  \n",
       "9                              Better than the real!!  \n",
       "10  Absolutely AWESOME! I was speechless when I tr...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>kcal</th>\n",
       "      <th>fat</th>\n",
       "      <th>sugar</th>\n",
       "      <th>salt</th>\n",
       "      <th>protein</th>\n",
       "      <th>sat_fat</th>\n",
       "      <th>carbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55.0</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "      <td>51.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "      <td>173.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name      id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style  137739     55.0   \n",
       "1            a bit different  breakfast pizza   31490     30.0   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           26278  2002-06-17   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                   nutrition  n_steps  \\\n",
       "0      [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1  [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "1  this recipe calls for the crust to be prebaked...   \n",
       "\n",
       "                                         ingredients  n_ingredients   kcal  \\\n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7   51.5   \n",
       "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  173.4   \n",
       "\n",
       "    fat sugar  salt protein sat_fat carbs  \n",
       "0   0.0  13.0   0.0     2.0     0.0   4.0  \n",
       "1  18.0   0.0  17.0    22.0    35.0   1.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering — User-based Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Collaborative Filtering (CF) is currently the most widely used approach to build recommendation systems  \n",
    ">- The key idea behind CF is that similar users have similar interests and that a user generally likes items that are similar to other items they like  \n",
    ">- CF is filling an \"empty cell\" in the utility matrix based on the similarity between users or item. Matrix factorization or decomposition can help us solve this problem by determining what the overall \"topics\" are when a matrix is factored\n",
    "  \n",
    "Note: We will likely need to bring this notebook over to DataBricks or AWS.  \n",
    "  \n",
    "We can use **cosine similarity** between users, or **Pearson Correlation Coefficient**. Different metrics will offer different results, but I don't see why we couldn't offer multiple recommendations using different metrics.\n",
    "\n",
    "**Note: Don't forget to downplay zeros as they are gaps, not values representative of sentiment!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD — Singular Value (Matrix) Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:  \n",
    "- eigendecompositions require square matrices\n",
    "- for SVD, we can create square matrices by taking the dot product of a matrix and its transpose\n",
    "- we can use SVD to draw vectors in a new space to capture as much of the variance in our data as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'recipe_id', 'date', 'rating', 'review'], dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~Below we use the raw interactions dataset to create the rating matrix `A`, with rows representing recipes and columns representing users.~  \n",
    "NVM LOOKS LIKE WE'RE GONNA NEED DISTRIBUTED COMPUTING FOR EVEN A SIMPLE SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 245. TiB for an array with shape (134728, 2000192946) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-181f9407e75c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m A = np.ndarray(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     dtype=np.uint8)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 245. TiB for an array with shape (134728, 2000192946) and data type uint8"
     ]
    }
   ],
   "source": [
    "A = np.ndarray(\n",
    "    shape=(np.max(idf.recipe_id.values), np.max(idf.user_id.values)),\n",
    "    dtype=np.uint8)\n",
    "\n",
    "A[idf.recipe_id.values-1, idf.user_id.values-1] = idf.rating.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with our smaller prepackaged training set—`tdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 979. TiB for an array with shape (537458, 2002312797) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-88715438d4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m A = np.ndarray(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     dtype=np.uint8)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 979. TiB for an array with shape (537458, 2002312797) and data type uint8"
     ]
    }
   ],
   "source": [
    "A = np.ndarray(\n",
    "    shape=(np.max(tdf.recipe_id.values), np.max(tdf.user_id.values)),\n",
    "    dtype=np.uint8)\n",
    "\n",
    "A[tdf.recipe_id.values-1, tdf.user_id.values-1] = tdf.rating.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$_{my}$ $_{poor}$ $_{memories.}$ $_{they're}$ $_{that}$ $_{I}$ $_{all}$ $_{I}$ $_{have}$ ._.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS — Alternating Lease Squares Matrix Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plug in guess values for P and Q\n",
    "- hold the values of one constant, then use the values for R and the non-constant to find the optimum values for.\n",
    "- repeat for the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"When we talk about collaborative filtering for recommender systems we want to solve the problem of our original matrix having millions of different dimensions, but our 'tastes' not being nearly as complex. Even if i’ve \\[sic\\] viewed hundreds of items they might just express a couple of different tastes. Here we can actually use matrix factorization to mathematically reduce the dimensionality of our original 'all users by all items' matrix into something much smaller that represents 'all items by some taste dimensions' and 'all users by some taste dimensions'. These dimensions are called ***latent or hidden features*** and we learn them from our data\" ([Medium article: \"ALS Implicit Collaborative Filtering\"](https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For collaborative ALS, we will want our data to be shaped something like below, where the column numbers represent Recipe ID:                                            \n",
    " \n",
    "User    | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 |...| n  \n",
    ":-------|:--|---|---|---|---|---|---|---|---|---|---|---|---|---|---:  \n",
    "user_01 | 0 | 0 | 5 | 4 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 | 0 | 0  \n",
    "user_02 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  \n",
    "user_03 | 5 | 0 | 0 | 0 | 5 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 5 | 0 | 0  \n",
    "user_04 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  \n",
    "user_05 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 | 0 | 0  \n",
    "user_06 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0  \n",
    "user_07 | 0 | 0 | 5 | 0 | 0 | 0 | 5 | 0 | 0 | 0 | 5 | 0 | 0 | 0 | 0  \n",
    "  ...   |  |  |  |  |  |  |  | ... |  |  |  |  |  |  | ...  \n",
    "user_n  | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 | 0 | 0  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based Rec. System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will split our RAW Interactions data in to a training dataset and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'raw_ratings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-c25be0d61e3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1984\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/surprise/model_selection/split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(data, test_size, train_size, random_state, shuffle)\u001b[0m\n\u001b[1;32m    332\u001b[0m     ss = ShuffleSplit(n_splits=1, test_size=test_size, train_size=train_size,\n\u001b[1;32m    333\u001b[0m                       random_state=random_state, shuffle=shuffle)\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/surprise/model_selection/split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         test_size, train_size = self.validate_train_test_sizes(\n\u001b[0;32m--> 276\u001b[0;31m             self.test_size, self.train_size, len(data.raw_ratings))\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'raw_ratings'"
     ]
    }
   ],
   "source": [
    "trainset, testset = train_test_split(idf, test_size = 0.2, random_state = 1984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:  \n",
    ">(*Both personalized and content-based recommendation systems*) make use of different similarity metrics to determine how \"similar\" items are to one another. The most common similarity metrics are [**Euclidean distance**](https://en.wikipedia.org/wiki/Euclidean_distance), [**cosine similarity**](https://en.wikipedia.org/wiki/Cosine_similarity), [**Pearson correlation**](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) and the [**Jaccard index**](https://en.wikipedia.org/wiki/Jaccard_index) (useful with binary data). Each one of these distance metrics has its advantages and disadvantages depending on the type of ratings you are using and the characteristics of your data.$_1$  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those of you visiting this page who are interested in reading more about recommender systems, below are fantastic resources that I have collected.  \n",
    "$_n$$_o$$_w$ &nbsp;$_I$ &nbsp;$_a$$_m$ &nbsp;$_t$$_h$$_e$ &nbsp;$_r$$_e$$_c$$_o$$_m$$_m$$_e$$_n$$_d$$_a$$_t$$_i$$_o$$_n$ &nbsp;$_s$$_y$$_s$$_t$$_e$$_m$$_!$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[*Mining Massive Datasets: Chapter 9*](http://infolab.stanford.edu/~ullman/mmds/ch9.pdf), © Copyright Stanford University. Stanford, California 94305  \n",
    "[Singular Value Decomposition (SVD) & Its Application In Recommender System](https://analyticsindiamag.com/singular-value-decomposition-svd-application-recommender-system/), Dr. Vaibhav Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [*Introduction to Recommender Systems* by Flatiron School](https://github.com/learn-co-curriculum/dsc-recommendation-system-introduction) is licensed under CC BY-NC-SA 4.0\n",
    ">© 2018 Flatiron School, Inc.  \n",
    ">© 2021 Flatiron School, LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
